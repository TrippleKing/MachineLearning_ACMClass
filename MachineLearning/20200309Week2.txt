ACM班 《机器学习》   Week2

线性模型    12:55——13:50

判别模型与生成模型

判别模型：
对可观测变量和未知变量的关联性建模
也称条件模型
确定性判别：y=f(x;theta)
随机判别：p_theta(y|x)

生成模型：
建模数据的联合概率分布
给定一些隐参数或隐变量p_theta(x,y)
进行条件推断
p_theta(y|x)=p_theta(x,y)/p_theta(x)


线性回归 linear regression

一维的线性回归和二次回归（都是线性模型）

学习目标
使预测值和真实值的距离越近越好

损失函数测量预测值和真实值之间的误差，越小越好

具体损失函数的定义依赖于具体的数据和任务

最广泛使用的损失函数：均方误差（MSE）

均方误差：对预测误差大的有更大的惩罚；容忍很小的预测误差（观测误差等；提升模型的泛化能力）


梯度更新方式
批量梯度下降、随机梯度下降、小批量梯度下降

批量梯度下降，根据整个批量数据的梯度更新参数

随机梯度下降，根据一条数据样本的梯度更新参数（更快地更新参数；学习中会产生震荡）  14:00——14:45

小批量梯度下降，将整个数据集分成K个小批量，对每一个小批量的梯度更新参数（结合上述两者）
结合了批量梯度下降和随机梯度下降的优点：
1. 批量梯度下降的优秀的稳定性
2. 随机梯度下降的快速更新

小批量梯度下降很容易做并行化：
将每个小批量数据进一步切分，每个线程分别计算梯度，最后再加和这些梯度

基本搜索步骤：
1.随机选择一个参数初始化θ
2.根据数据和梯度算法更新θ
3.直到走到局部一个最小区域local minimum


线性回归矩阵形式（注意理解其在空间上所表达的含义）

泛线性模型   14:55——15:50
存在特征映射

判别模型
最大似然估计 → 本质上依然是MSE


分类指标

（二分类）预测：1/0；标签：1/0

                    预测
             1                0
    
     1 True Positive     False Negative

标签

     0 False Positive    True Negative


准确率（precision）：Prec=TP/(TP+FP)

召回率（Recall）： Rec=TP/(TP+FN)

F1-score：F1 = 2*Prec*Rec/(Prec+Rec)

准确率和召回率的权衡

阈值越高，准确率越低，召回率越低

阈值越低，准确率越低，召回率越高

F1度量

F1 = 2*(Prec*Rec)/(Prec+Rec)

基于排序的度量:ROC曲线下面积(AUC)

纵坐标：True Positive Rate

横坐标：False Positive Rate






